{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YU-DroYpPQX1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The list of functions and where they can be integrated in the model are in the loss function report version 1\n",
        "# Dice Loss\n",
        "def dice_loss(pred, target, smooth=1e-5):\n",
        "    pred_flat = pred.view(-1)\n",
        "    target_flat = target.view(-1)\n",
        "    intersection = (pred_flat * target_flat).sum()\n",
        "    return 1 - (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n",
        "\n",
        "# Boundary Loss\n",
        "def boundary_loss(pred, target):\n",
        "    sobel_filter = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).float().unsqueeze(0).unsqueeze(0)\n",
        "    if torch.cuda.is_available():\n",
        "        sobel_filter = sobel_filter.cuda()\n",
        "\n",
        "    pred_grad = F.conv2d(pred, sobel_filter, padding=1)\n",
        "    target_grad = F.conv2d(target, sobel_filter, padding=1)\n",
        "    loss = F.mse_loss(pred_grad, target_grad)\n",
        "    return loss\n",
        "\n",
        "# KL Divergence Loss\n",
        "def kl_divergence_loss(pred_distribution, target_distribution):\n",
        "    pred_distribution = F.log_softmax(pred_distribution, dim=1)\n",
        "    target_distribution = F.softmax(target_distribution, dim=1)\n",
        "    return F.kl_div(pred_distribution, target_distribution, reduction='batchmean')\n",
        "\n",
        "# Hausdorff Distance Loss\n",
        "def hausdorff_distance_loss(pred, target):\n",
        "    pred_flat = pred.view(-1)\n",
        "    target_flat = target.view(-1)\n",
        "    return torch.abs(pred_flat - target_flat).mean()\n",
        "\n",
        "# Shape Alignment Loss\n",
        "def shape_alignment_loss(pred, target):\n",
        "    return F.mse_loss(pred, target)\n"
      ],
      "metadata": {
        "id": "5TgAQjHcQJs0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using a Simple CNN just for convenience while implementing the loss function\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.sigmoid(self.conv3(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "OnOWLPu3QLcw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IoU Metric\n",
        "def iou_metric(pred, target):\n",
        "    pred_binary = (pred > 0.5).float()\n",
        "    target_binary = (target > 0.5).float()\n",
        "    intersection = (pred_binary * target_binary).sum(dim=(1, 2, 3))\n",
        "    union = (pred_binary + target_binary).sum(dim=(1, 2, 3)) - intersection\n",
        "    iou = intersection / (union + 1e-5)\n",
        "    return iou.mean().item()\n",
        "\n",
        "# Dummy Data (Planning to replace this soon using cardiac data)\n",
        "def generate_dummy_data(batch_size=16, image_size=64):\n",
        "    images = torch.rand(batch_size, 1, image_size, image_size)\n",
        "    masks = torch.randint(0, 2, (batch_size, 1, image_size, image_size)).float()\n",
        "    if torch.cuda.is_available():\n",
        "        images, masks = images.cuda(), masks.cuda()\n",
        "    return images, masks\n"
      ],
      "metadata": {
        "id": "BNN23kQ4QNKm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train(model, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    images, masks = generate_dummy_data()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = loss_fn(outputs, masks)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation Loop\n",
        "def evaluate(model, loss_fn):\n",
        "    model.eval()\n",
        "    images, masks = generate_dummy_data()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, masks)\n",
        "        iou = iou_metric(outputs, masks)\n",
        "    return loss.item(), iou"
      ],
      "metadata": {
        "id": "dc4qOsGwQO46"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Loss Functions to Test\n",
        "loss_functions = {\n",
        "    \"Dice Loss\": dice_loss,\n",
        "    \"Boundary Loss\": boundary_loss,\n",
        "    \"KL Divergence Loss\": kl_divergence_loss,\n",
        "    \"Hausdorff Distance Loss\": hausdorff_distance_loss,\n",
        "    \"Shape Alignment Loss\": shape_alignment_loss\n",
        "}\n",
        "\n",
        "# Evaluation for each loss function separately, next step is to do a grid search for the optimal compound loss function\n",
        "results = {}\n",
        "for loss_name, loss_fn in loss_functions.items():\n",
        "    print(f\"\\nUsing {loss_name}...\")\n",
        "    train_loss = train(model, optimizer, loss_fn)\n",
        "    eval_loss, eval_iou = evaluate(model, loss_fn)\n",
        "    results[loss_name] = {\"Train Loss\": train_loss, \"Eval Loss\": eval_loss, \"Eval IoU\": eval_iou}\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Evaluation Loss: {eval_loss:.4f}\")\n",
        "    print(f\"Evaluation IoU: {eval_iou:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oekVm_nBQQrL",
        "outputId": "6c6777b4-74aa-426f-d794-1e9ff78b6463"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using Dice Loss...\n",
            "Training Loss: 0.4980\n",
            "Evaluation Loss: 0.4939\n",
            "Evaluation IoU: 0.4872\n",
            "\n",
            "Using Boundary Loss...\n",
            "Training Loss: 2.9291\n",
            "Evaluation Loss: 2.9906\n",
            "Evaluation IoU: 0.4925\n",
            "\n",
            "Using KL Divergence Loss...\n",
            "Training Loss: 0.0000\n",
            "Evaluation Loss: 0.0000\n",
            "Evaluation IoU: 0.4949\n",
            "\n",
            "Using Hausdorff Distance Loss...\n",
            "Training Loss: 0.5001\n",
            "Evaluation Loss: 0.5000\n",
            "Evaluation IoU: 0.4962\n",
            "\n",
            "Using Shape Alignment Loss...\n",
            "Training Loss: 0.2512\n",
            "Evaluation Loss: 0.2514\n",
            "Evaluation IoU: 0.4939\n"
          ]
        }
      ]
    }
  ]
}