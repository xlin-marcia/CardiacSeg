{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install monai"
      ],
      "metadata": {
        "id": "8WS2z0WR8aXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmxbOGIC4Imu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from monai.losses import DiceLoss\n",
        "from scipy.ndimage import zoom\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Directory\n",
        "DATASET_DIR = \"/content/drive/MyDrive/NTU/ACDC_Dataset\"\n",
        "\n",
        "def parse_cfg(cfg_path):\n",
        "    with open(cfg_path, \"r\") as file:\n",
        "        cfg_data = {}\n",
        "        for line in file:\n",
        "            key, value = line.strip().split(\": \")\n",
        "            cfg_data[key] = value\n",
        "    return int(cfg_data[\"ED\"]), int(cfg_data[\"ES\"]), cfg_data[\"Group\"]\n",
        "\n",
        "class ACDCDataset(Dataset):\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patient_dir = self.file_list[idx]\n",
        "        cfg_path = os.path.join(patient_dir, \"Info.cfg\")\n",
        "        ed_frame, _, _ = parse_cfg(cfg_path)\n",
        "\n",
        "        patient_id = os.path.basename(patient_dir)[-3:]\n",
        "        ed_image_path = os.path.join(patient_dir, f\"patient{patient_id}_frame{ed_frame:02d}.nii.gz\")\n",
        "        ed_label_path = os.path.join(patient_dir, f\"patient{patient_id}_frame{ed_frame:02d}_gt.nii.gz\")\n",
        "\n",
        "        ed_image = nib.load(ed_image_path).get_fdata()\n",
        "        ed_label = nib.load(ed_label_path).get_fdata()\n",
        "\n",
        "        def preprocess(image, label):\n",
        "            image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "            label = label.astype(np.int32)\n",
        "            image = zoom(image, (128 / image.shape[0], 128 / image.shape[1], 64 / image.shape[2]), order=1)\n",
        "            label = zoom(label, (128 / label.shape[0], 128 / label.shape[1], 64 / label.shape[2]), order=0)\n",
        "            return image, label\n",
        "\n",
        "        ed_image, ed_label = preprocess(ed_image, ed_label)\n",
        "        ed_label = np.expand_dims(ed_label, axis=0)\n",
        "\n",
        "        sample = {\"image\": torch.tensor(ed_image[None, ...], dtype=torch.float32),\n",
        "                  \"label\": torch.tensor(ed_label, dtype=torch.long)}\n",
        "        return sample\n",
        "\n",
        "# Prepare the dataset and data loaders.\n",
        "patients = [os.path.join(DATASET_DIR, \"training\", d)\n",
        "            for d in os.listdir(os.path.join(DATASET_DIR, \"training\")) if d.startswith(\"patient\")]\n",
        "train_patients, val_patients = train_test_split(patients, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = ACDCDataset(train_patients)\n",
        "val_dataset   = ACDCDataset(val_patients)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "N4D0BJzA4-8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def window_partition(x, window_size):\n",
        "    \"\"\"\n",
        "    Partition a 5D tensor (B, H, W, D, C) into non-overlapping windows.\n",
        "    \"\"\"\n",
        "    B, H, W, D, C = x.shape\n",
        "    w1, w2, w3 = window_size\n",
        "    x = x.view(B, H // w1, w1,\n",
        "                  W // w2, w2,\n",
        "                  D // w3, w3, C)\n",
        "    windows = x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous()\n",
        "    windows = windows.view(-1, w1 * w2 * w3, C)\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, B, H, W, D):\n",
        "    \"\"\"\n",
        "    Reverse the window partition to reconstruct the original tensor.\n",
        "    \"\"\"\n",
        "    w1, w2, w3 = window_size\n",
        "    x = windows.view(B, H // w1, W // w2, D // w3, w1, w2, w3, -1)\n",
        "    x = x.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous()\n",
        "    x = x.view(B, H, W, D, -1)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "L6zc37Ne4-_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinTransformerBlock3D(nn.Module):\n",
        "    def __init__(self, embed_dim, window_size, num_heads, dropout=0.1, mlp_ratio=4.0):\n",
        "        super(SwinTransformerBlock3D, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(int(embed_dim * mlp_ratio), embed_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, H, W, D):\n",
        "        B, N, C = x.shape\n",
        "        # Reshape token sequence into 5D tensor.\n",
        "        x = x.view(B, H, W, D, C)\n",
        "        windows = window_partition(x, self.window_size)  # (B*num_windows, window_volume, C)\n",
        "        windows = self.norm1(windows)\n",
        "        attn_windows, _ = self.attn(windows, windows, windows)\n",
        "        windows = windows + attn_windows\n",
        "        windows = windows + self.mlp(self.norm2(windows))\n",
        "        x = window_reverse(windows, self.window_size, B, H, W, D)\n",
        "        x = x.view(B, N, C)\n",
        "        return x\n",
        "\n",
        "class SwinViTSegmentation(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=4, embed_dim=128,\n",
        "                 patch_size=(16, 16, 16), window_size=(2, 2, 2),\n",
        "                 num_layers=2, num_heads=4, dropout=0.1, img_size=(128, 128, 64)):\n",
        "        super(SwinViTSegmentation, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        # Patch embedding\n",
        "        self.patch_embed = nn.Conv3d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1], img_size[2] // patch_size[2])\n",
        "        num_patches = grid_size[0] * grid_size[1] * grid_size[2]\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        self.layers = nn.ModuleList([\n",
        "            SwinTransformerBlock3D(embed_dim, window_size, num_heads, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        # Segmentation head (1x1 convolution)\n",
        "        self.seg_head = nn.Conv3d(embed_dim, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, in_channels, H, W, D)\n",
        "        x = self.patch_embed(x)  # -> (B, embed_dim, H_patch, W_patch, D_patch)\n",
        "        B, C, H_patch, W_patch, D_patch = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, N, C)\n",
        "        x = x + self.pos_embed\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, H_patch, W_patch, D_patch)\n",
        "        x = x.transpose(1, 2).view(B, C, H_patch, W_patch, D_patch)\n",
        "        logits = self.seg_head(x)  # (B, num_classes, H_patch, W_patch, D_patch)\n",
        "        logits = F.interpolate(logits, scale_factor=self.patch_size, mode='trilinear', align_corners=False)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "-F2IC01s5TPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Functions\n",
        "\n",
        "def dice_loss(output, target):\n",
        "    return DiceLoss(to_onehot_y=True, softmax=True)(output, target)\n",
        "\n",
        "def cross_entropy_loss(output, target):\n",
        "    target = target.squeeze(1)\n",
        "    return F.cross_entropy(output, target)\n",
        "\n",
        "def normal_consistency_loss(output, target):\n",
        "    output_grad = torch.gradient(output, dim=(2, 3, 4))\n",
        "    target_grad = torch.gradient(target.float(), dim=(2, 3, 4))\n",
        "    loss = 0.0\n",
        "    for og, tg in zip(output_grad, target_grad):\n",
        "        loss += F.l1_loss(og, tg)\n",
        "    return loss / len(output_grad)\n",
        "\n",
        "def wasserstein_distance_loss(output, target):\n",
        "    output = F.softmax(output, dim=1)\n",
        "    output_flat = output.view(output.size(0), output.size(1), -1)\n",
        "    target_one_hot = F.one_hot(target.squeeze(1), num_classes=output.size(1)).permute(0, 4, 1, 2, 3)\n",
        "    target_flat = target_one_hot.reshape(output.size(0), output.size(1), -1).float()\n",
        "    cdf_output = torch.cumsum(output_flat, dim=-1)\n",
        "    cdf_target = torch.cumsum(target_flat, dim=-1)\n",
        "    return torch.abs(cdf_output - cdf_target).mean()\n",
        "\n",
        "def hausdorff_loss(output, target):\n",
        "    output_soft = F.softmax(output, dim=1)\n",
        "    preds = torch.argmax(output_soft, dim=1)\n",
        "    loss = 0.0\n",
        "    B, C, H, W, D = output.shape[0], output.shape[1], output.shape[2], output.shape[3], output.shape[4]\n",
        "    for b in range(B):\n",
        "        for c in range(C):\n",
        "            gt_mask = (target[b, 0] == c).float().unsqueeze(0).unsqueeze(0)\n",
        "            pred_mask = (preds[b] == c).float().unsqueeze(0).unsqueeze(0)\n",
        "            kernel_size = 3\n",
        "            gt_pool = F.max_pool3d(gt_mask, kernel_size=kernel_size, stride=1, padding=1)\n",
        "            pred_pool = F.max_pool3d(pred_mask, kernel_size=kernel_size, stride=1, padding=1)\n",
        "            gt_boundary = gt_mask - (gt_mask * (gt_mask == gt_pool).float())\n",
        "            pred_boundary = pred_mask - (pred_mask * (pred_mask == pred_pool).float())\n",
        "            gt_coords = (gt_boundary[0, 0] > 0).nonzero(as_tuple=False).float()\n",
        "            pred_coords = (pred_boundary[0, 0] > 0).nonzero(as_tuple=False).float()\n",
        "            if gt_coords.numel() == 0 or pred_coords.numel() == 0:\n",
        "                continue\n",
        "            dists = torch.cdist(pred_coords, gt_coords, p=2)\n",
        "            hd_pred_to_gt = dists.min(dim=1)[0].max()\n",
        "            hd_gt_to_pred = dists.min(dim=0)[0].max()\n",
        "            hd = torch.max(hd_pred_to_gt, hd_gt_to_pred)\n",
        "            loss += hd\n",
        "    return loss / (B * C)\n",
        "\n",
        "# Compound loss variants\n",
        "def compound_loss_variant1(output, target, weights):\n",
        "    \"\"\"\n",
        "    Variant 1: CE + NC + Hausdorff + Dice.\n",
        "    Weights is a tuple of four values.\n",
        "    \"\"\"\n",
        "    ce = cross_entropy_loss(output, target)\n",
        "    nc = normal_consistency_loss(output, target)\n",
        "    hd = hausdorff_loss(output, target)\n",
        "    d  = dice_loss(output, target)\n",
        "    return weights[0]*ce + weights[1]*nc + weights[2]*hd + weights[3]*d\n",
        "\n",
        "def compound_loss_variant2(output, target, weights):\n",
        "    \"\"\"\n",
        "    Variant 2: CE + NC + Wasserstein + Dice.\n",
        "    \"\"\"\n",
        "    ce = cross_entropy_loss(output, target)\n",
        "    nc = normal_consistency_loss(output, target)\n",
        "    wd = wasserstein_distance_loss(output, target)\n",
        "    d  = dice_loss(output, target)\n",
        "    return weights[0]*ce + weights[1]*nc + weights[2]*wd + weights[3]*d\n"
      ],
      "metadata": {
        "id": "9o4536ER5X24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(preds, targets, num_classes):\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    iou_scores = []\n",
        "    for cls in range(num_classes):\n",
        "        pred_mask = (preds == cls).float()\n",
        "        target_mask = (targets.squeeze(1) == cls).float()\n",
        "        intersection = (pred_mask * target_mask).sum()\n",
        "        union = (pred_mask + target_mask).clamp(0, 1).sum()\n",
        "        if union == 0:\n",
        "            iou_scores.append(torch.tensor(1.0, device=preds.device))\n",
        "        else:\n",
        "            iou_scores.append(intersection / union)\n",
        "    return torch.mean(torch.stack(iou_scores))\n",
        "\n",
        "def pixel_accuracy(preds, targets):\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    correct = (preds == targets.squeeze(1)).sum().item()\n",
        "    total = torch.numel(targets)\n",
        "    return correct / total\n",
        "\n",
        "def precision_recall(preds, targets, num_classes):\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    precision, recall = [], []\n",
        "    for cls in range(num_classes):\n",
        "        tp = ((preds == cls) & (targets.squeeze(1) == cls)).sum().item()\n",
        "        fp = ((preds == cls) & (targets.squeeze(1) != cls)).sum().item()\n",
        "        fn = ((preds != cls) & (targets.squeeze(1) == cls)).sum().item()\n",
        "        precision.append(tp / (tp + fp + 1e-7))\n",
        "        recall.append(tp / (tp + fn + 1e-7))\n",
        "    return sum(precision) / len(precision), sum(recall) / len(recall)\n",
        "\n",
        "def dice_coefficient(preds, targets):\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    dice_scores = []\n",
        "    for cls in range(preds.max().item() + 1):\n",
        "        pred_mask = (preds == cls).float()\n",
        "        target_mask = (targets.squeeze(1) == cls).float()\n",
        "        intersection = (pred_mask * target_mask).sum()\n",
        "        dice = (2 * intersection) / (pred_mask.sum() + target_mask.sum() + 1e-7)\n",
        "        dice_scores.append(dice)\n",
        "    return sum(dice_scores) / len(dice_scores)"
      ],
      "metadata": {
        "id": "OzOofdB35YiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search Setup\n",
        "\n",
        "# Define candidate weight sets (for the 4 loss components)\n",
        "candidate_weights = [\n",
        "    (0.25, 0.25, 0.25, 0.25),\n",
        "    (0.20, 0.30, 0.30, 0.20),\n",
        "    (0.30, 0.20, 0.20, 0.30),\n",
        "    (0.10, 0.40, 0.40, 0.10)\n",
        "]\n",
        "\n",
        "# grid search parameters\n",
        "NUM_EPOCHS = 10\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# For each variant, we will store the best candidate (according validation Dice coefficient)\n",
        "best_config = {\n",
        "    \"Variant1\": {\"weights\": None, \"dice\": 0.0},\n",
        "    \"Variant2\": {\"weights\": None, \"dice\": 0.0}\n",
        "}\n",
        "\n",
        "# to train and evaluate for a given compound loss function\n",
        "def train_and_evaluate(compound_loss_fn, weights, variant_name):\n",
        "    model = SwinViTSegmentation(\n",
        "        in_channels=1,\n",
        "        num_classes=4,\n",
        "        embed_dim=128,\n",
        "        patch_size=(16, 16, 16),\n",
        "        window_size=(2, 2, 2),\n",
        "        num_layers=2,\n",
        "        num_heads=4,\n",
        "        dropout=0.1,\n",
        "        img_size=(128, 128, 64)\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            images = batch[\"image\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = compound_loss_fn(outputs, labels, weights)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"[{variant_name} | Weights {weights}] Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    model.eval()\n",
        "    val_iou = 0.0\n",
        "    val_dice = 0.0\n",
        "    val_pix_acc = 0.0\n",
        "    val_prec = 0.0\n",
        "    val_rec = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch[\"image\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            val_iou += compute_iou(outputs, labels, num_classes=4).item()\n",
        "            val_dice += dice_coefficient(outputs, labels).item()\n",
        "            val_pix_acc += pixel_accuracy(outputs, labels)\n",
        "            p, r = precision_recall(outputs, labels, num_classes=4)\n",
        "            val_prec += p\n",
        "            val_rec  += r\n",
        "    num_batches = len(val_loader)\n",
        "    avg_iou = val_iou / num_batches\n",
        "    avg_dice = val_dice / num_batches\n",
        "    avg_pix_acc = val_pix_acc / num_batches\n",
        "    avg_prec = val_prec / num_batches\n",
        "    avg_rec = val_rec / num_batches\n",
        "    print(f\"[{variant_name} | Weights {weights}] Validation Metrics -- IoU: {avg_iou:.4f}, Dice: {avg_dice:.4f}, Pixel Acc: {avg_pix_acc:.4f}, Prec: {avg_prec:.4f}, Rec: {avg_rec:.4f}\")\n",
        "\n",
        "    return avg_dice # For example, we use Dice coefficient as the selection metric"
      ],
      "metadata": {
        "id": "3s73sgPF5jRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variant 1: CE + NC + Hausdorff + Dice\n",
        "print(\"\\n=== Grid Search for Compound Loss Variant 1 (CE + NC + Hausdorff + Dice) ===\\n\")\n",
        "for weights in candidate_weights:\n",
        "    avg_dice = train_and_evaluate(compound_loss_variant1, weights, \"Variant1\")\n",
        "    if avg_dice > best_config[\"Variant1\"][\"dice\"]:\n",
        "        best_config[\"Variant1\"][\"dice\"] = avg_dice\n",
        "        best_config[\"Variant1\"][\"weights\"] = weights\n",
        "\n",
        "# Variant 2: CE + NC + Wasserstein + Dice\n",
        "print(\"\\n=== Grid Search for Compound Loss Variant 2 (CE + NC + Wasserstein + Dice) ===\\n\")\n",
        "for weights in candidate_weights:\n",
        "    avg_dice = train_and_evaluate(compound_loss_variant2, weights, \"Variant2\")\n",
        "    if avg_dice > best_config[\"Variant2\"][\"dice\"]:\n",
        "        best_config[\"Variant2\"][\"dice\"] = avg_dice\n",
        "        best_config[\"Variant2\"][\"weights\"] = weights\n",
        "\n",
        "print(\"\\n=== Grid Search Results ===\")\n",
        "print(\"Best configuration for Variant 1 (CE + NC + Hausdorff + Dice):\")\n",
        "print(best_config[\"Variant1\"])\n",
        "print(\"Best configuration for Variant 2 (CE + NC + Wasserstein + Dice):\")\n",
        "print(best_config[\"Variant2\"])"
      ],
      "metadata": {
        "id": "5gRBpofl5m0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}